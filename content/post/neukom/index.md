---
title: "A Deep Learning Approach to Understanding Real-World Scene Perception in Autism"
subtitle: "Undergraduate honors thesis in cognitive science (high honors)"
tags: ["VR Gaze"]
date: "2020-05-27T00:00:00Z"

---
## Abstract
Around 90% of individuals with autism experience sensory sensitivities, but our understanding of these symptoms is limited by past studies' unrealistic experimental designs and unreproducible results. We use a novel combination of virtual reality, eyetracking, and convolutional neural networks to model the staged of visual processing that predict differences in visual attention between individuals with and without autism. We find that even the earliest stages of the model can predict differences in gaze behavior between autists and controls. This suggests that visual processing differences in autism are not principally driven by the semantically-meaningful features within a scene but emerge from differences in early visual processing. 

This project was advised by [Caroline Robertson](https://www.robertsonlab.com/caroline) (Dartmouth College PBS) and [Leyla Isik](https://cogsci.jhu.edu/directory/leyla-isik/) (Johns Hopkins University Cognitive Science).

[Full text here.](/static/files/Busch_Neukom_Undergrad_Submission.pdf)